{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNc3hO31gK5Dm+ZEuFQYaUY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masciel-Sevilla/modelos/blob/main/Completo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XdkIbf9fGbE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50dc4685-5197-46ce-d76e-4cb58aff7e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/lucasb-eyer/pydensecrf.git\n",
            "  Cloning https://github.com/lucasb-eyer/pydensecrf.git to /tmp/pip-req-build-i79_xle1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lucasb-eyer/pydensecrf.git /tmp/pip-req-build-i79_xle1\n",
            "  Resolved https://github.com/lucasb-eyer/pydensecrf.git to commit 2723c7fa4f2ead16ae1ce3d8afe977724bb8f87f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Modelo cargado exitosamente.\n",
            "\n",
            "Iniciando evaluación comparativa (Normal, CRF, TTA)...\n",
            "\n",
            "--- Resultados Detallados por Clase y Técnica ---\n",
            "Clase           | IoU Normal   | IoU con CRF  | IoU con TTA \n",
            "-----------------------------------------------------------------\n",
            "Background      | 0.9491       | 0.9524       | 0.9501      \n",
            "Cow-tongue      | 0.9056       | 0.8957       | 0.9074      \n",
            "Dandelion       | 0.8930       | 0.8884       | 0.8942      \n",
            "Kikuyo          | 0.8937       | 0.8864       | 0.8978      \n",
            "Other           | 0.7087       | 0.7068       | 0.7097      \n",
            "Potato          | 0.8881       | 0.8832       | 0.9032      \n",
            "-----------------------------------------------------------------\n",
            "mIoU Promedio   | 0.8730       | 0.8688       | 0.8771      \n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# PASO 1: INSTALAR LIBRERÍAS\n",
        "# ==============================================================================\n",
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "\n",
        "# ==============================================================================\n",
        "# PASO 2: IMPORTAR LIBRERÍAS\n",
        "# ==============================================================================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from glob import glob\n",
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral, create_pairwise_gaussian\n",
        "\n",
        "# ==============================================================================\n",
        "# PASO 3: CONFIGURACIÓN Y RUTAS\n",
        "# ==============================================================================\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "NUM_CLASSES = 6\n",
        "CLASS_NAMES = ['Background', 'Cow-tongue', 'Dandelion', 'Kikuyo', 'Other', 'Potato']\n",
        "MODEL_SAVE_PATH = 'efficient_weed_model_S.keras'\n",
        "BASE_PATH = './Balanced'\n",
        "VAL_IMAGES_PATH = os.path.join(BASE_PATH, 'val/images')\n",
        "VAL_MASKS_PATH = os.path.join(BASE_PATH, 'val/masks')\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# PASO 4: DEFINICIONES COMPLETAS PARA CARGAR EL MODELO\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Clases personalizadas (IMPLEMENTACIÓN COMPLETA Y CORRECTA) ---\n",
        "class ASPPModule(layers.Layer):\n",
        "    def __init__(self, filters=192, **kwargs):\n",
        "        super(ASPPModule, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.conv_1x1 = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1 = layers.BatchNormalization()\n",
        "        self.relu_1x1 = layers.ReLU()\n",
        "        self.conv_3x3_6 = layers.Conv2D(filters, 3, padding='same', dilation_rate=6, use_bias=False)\n",
        "        self.bn_3x3_6 = layers.BatchNormalization()\n",
        "        self.relu_3x3_6 = layers.ReLU()\n",
        "        self.conv_3x3_12 = layers.Conv2D(filters, 3, padding='same', dilation_rate=12, use_bias=False)\n",
        "        self.bn_3x3_12 = layers.BatchNormalization()\n",
        "        self.relu_3x3_12 = layers.ReLU()\n",
        "        self.conv_3x3_18 = layers.Conv2D(filters, 3, padding='same', dilation_rate=18, use_bias=False)\n",
        "        self.bn_3x3_18 = layers.BatchNormalization()\n",
        "        self.relu_3x3_18 = layers.ReLU()\n",
        "        self.global_avg_pool = layers.GlobalAveragePooling2D(keepdims=True)\n",
        "        self.conv_1x1_gap = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1_gap = layers.BatchNormalization()\n",
        "        self.relu_1x1_gap = layers.ReLU()\n",
        "        self.conv_final = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_final = layers.BatchNormalization()\n",
        "        self.relu_final = layers.ReLU()\n",
        "        self.dropout = layers.Dropout(0.2)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        conv_1x1 = self.relu_1x1(self.bn_1x1(self.conv_1x1(inputs), training=training))\n",
        "        conv_3x3_6 = self.relu_3x3_6(self.bn_3x3_6(self.conv_3x3_6(inputs), training=training))\n",
        "        conv_3x3_12 = self.relu_3x3_12(self.bn_3x3_12(self.conv_3x3_12(inputs), training=training))\n",
        "        conv_3x3_18 = self.relu_3x3_18(self.bn_3x3_18(self.conv_3x3_18(inputs), training=training))\n",
        "        gap = self.global_avg_pool(inputs)\n",
        "        gap = self.relu_1x1_gap(self.bn_1x1_gap(self.conv_1x1_gap(gap), training=training))\n",
        "        gap = tf.image.resize(gap, [input_shape[1], input_shape[2]], method='bilinear')\n",
        "        concat = layers.Concatenate()([conv_1x1, conv_3x3_6, conv_3x3_12, conv_3x3_18, gap])\n",
        "        output = self.relu_final(self.bn_final(self.conv_final(concat), training=training))\n",
        "        output = self.dropout(output, training=training)\n",
        "        return output\n",
        "\n",
        "class DeformableAttention(layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(DeformableAttention, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.attention_conv = layers.Conv2D(self.filters, 1, padding='same', activation='sigmoid', name='attention_weights_conv', use_bias=False)\n",
        "        self.bn_attention = layers.BatchNormalization()\n",
        "        self.feature_conv = layers.SeparableConv2D(self.filters, 3, padding='same', name='feature_processing_conv', use_bias=False)\n",
        "        self.bn_feature = layers.BatchNormalization()\n",
        "        self.relu_feature = layers.ReLU()\n",
        "        super(DeformableAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attention_weights = self.bn_attention(self.attention_conv(inputs), training=training)\n",
        "        features = self.relu_feature(self.bn_feature(self.feature_conv(inputs), training=training))\n",
        "        attended_features = features * attention_weights\n",
        "        return attended_features\n",
        "\n",
        "# --- Funciones personalizadas (placeholders para la carga)---\n",
        "def dice_coefficient(y_true, y_pred): return 0.0\n",
        "def combined_loss(y_true, y_pred): return 0.0\n",
        "\n",
        "def iou_per_class(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    if y_pred.shape[-1] != NUM_CLASSES: y_pred = tf.one_hot(tf.cast(y_pred, tf.int32), depth=NUM_CLASSES)\n",
        "    else: y_pred = tf.cast(y_pred, tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2]); union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2]) - intersection\n",
        "    return tf.squeeze(tf.where(tf.equal(union, 0), 1.0, intersection / union))\n",
        "\n",
        "def iou_metric(y_true, y_pred): return tf.reduce_mean(iou_per_class(y_true, y_pred))\n",
        "\n",
        "# --- Funciones de Post-Procesamiento ---\n",
        "def refine_segmentation_with_crf(image, softmax_output, crf_params):\n",
        "    image = np.ascontiguousarray(image); unary = unary_from_softmax(softmax_output); unary = np.ascontiguousarray(unary)\n",
        "    d = dcrf.DenseCRF2D(image.shape[1], image.shape[0], softmax_output.shape[0]); d.setUnaryEnergy(unary)\n",
        "    d.addPairwiseEnergy(create_pairwise_gaussian(sdims=(crf_params['g_sdims'], crf_params['g_sdims']), shape=image.shape[:2]), compat=crf_params['g_compat'], kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
        "    d.addPairwiseEnergy(create_pairwise_bilateral(sdims=(crf_params['b_sdims'], crf_params['b_sdims']), schan=(crf_params['b_rgb_sdims'], crf_params['b_rgb_sdims'], crf_params['b_rgb_sdims']), img=image, chdim=2), compat=crf_params['b_compat'], kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
        "    Q = d.inference(crf_params['iterations']); return np.argmax(Q, axis=0).reshape((image.shape[0], image.shape[1]))\n",
        "\n",
        "def perform_segmentation_tta(model, image_tensor):\n",
        "    all_predictions = []\n",
        "    pred_original = model.predict(image_tensor, verbose=0); all_predictions.append(pred_original)\n",
        "    flipped_lr = tf.image.flip_left_right(image_tensor); pred_flipped_lr = model.predict(flipped_lr, verbose=0)\n",
        "    pred_original_lr = tf.image.flip_left_right(pred_flipped_lr); all_predictions.append(pred_original_lr)\n",
        "    flipped_ud = tf.image.flip_up_down(image_tensor); pred_flipped_ud = model.predict(flipped_ud, verbose=0)\n",
        "    pred_original_ud = tf.image.flip_up_down(pred_flipped_ud); all_predictions.append(pred_original_ud)\n",
        "    avg_preds = tf.reduce_mean(tf.stack(all_predictions), axis=0)\n",
        "    return avg_preds[0]\n",
        "\n",
        "# ==============================================================================\n",
        "# PASO 5: CARGAR DATOS Y EJECUTAR EVALUACIÓN\n",
        "# ==============================================================================\n",
        "def load_validation_data(val_img_path, val_msk_path):\n",
        "    val_image_paths = sorted(glob(os.path.join(val_img_path, '*.jpg')))\n",
        "    val_mask_paths = sorted(glob(os.path.join(val_msk_path, '*.png')))\n",
        "    if not val_image_paths or not val_mask_paths: raise FileNotFoundError(f\"No se encontraron imágenes o máscaras en: {val_img_path}, {val_msk_path}\")\n",
        "    val_ds_original = tf.data.Dataset.from_tensor_slices(val_image_paths).map(lambda p: tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(p), channels=3), [IMG_HEIGHT, IMG_WIDTH]))\n",
        "    val_ds_processed = val_ds_original.map(tf.keras.applications.efficientnet_v2.preprocess_input)\n",
        "    val_ds_masks = tf.data.Dataset.from_tensor_slices(val_mask_paths).map(lambda p: tf.one_hot(tf.squeeze(tf.cast(tf.image.resize(tf.image.decode_png(tf.io.read_file(p), channels=1), [IMG_HEIGHT, IMG_WIDTH], method='nearest'), tf.int32)), depth=NUM_CLASSES))\n",
        "    return tf.data.Dataset.zip((val_ds_original, val_ds_processed, val_ds_masks)).batch(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    custom_objects = {'combined_loss': combined_loss, 'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric, 'ASPPModule': ASPPModule, 'DeformableAttention': DeformableAttention}\n",
        "    try:\n",
        "        model = tf.keras.models.load_model(MODEL_SAVE_PATH, custom_objects=custom_objects)\n",
        "        print(\"Modelo cargado exitosamente.\")\n",
        "\n",
        "        val_dataset = load_validation_data(VAL_IMAGES_PATH, VAL_MASKS_PATH)\n",
        "        per_class_iou_normal_list, per_class_iou_crf_list, per_class_iou_tta_list = [], [], []\n",
        "        crf_params = { 'g_sdims': 3, 'g_compat': 1, 'b_sdims': 80, 'b_rgb_sdims': 13, 'b_compat':5, 'iterations': 5 }\n",
        "        print(\"\\nIniciando evaluación comparativa (Normal, CRF, TTA)...\")\n",
        "\n",
        "        for image_original, image_processed, mask_true_one_hot in val_dataset:\n",
        "            image_uint8 = tf.cast(image_original[0], tf.uint8).numpy()\n",
        "\n",
        "            # 1. Predicción Normal\n",
        "            probs_pred_normal = model.predict(image_processed, verbose=0)[0]\n",
        "            mask_pred_normal = np.argmax(probs_pred_normal, axis=-1)\n",
        "            iou_normal = iou_per_class(mask_true_one_hot, mask_pred_normal[np.newaxis, ...]); per_class_iou_normal_list.append(iou_normal.numpy())\n",
        "\n",
        "            # 2. Predicción con CRF\n",
        "            probs_for_crf = probs_pred_normal.transpose(2, 0, 1)\n",
        "            mask_pred_crf = refine_segmentation_with_crf(image_uint8, probs_for_crf, crf_params)\n",
        "            iou_crf = iou_per_class(mask_true_one_hot, mask_pred_crf[np.newaxis, ...]); per_class_iou_crf_list.append(iou_crf.numpy())\n",
        "\n",
        "            # 3. Predicción con TTA\n",
        "            probs_pred_tta = perform_segmentation_tta(model, image_processed)\n",
        "            mask_pred_tta = np.argmax(probs_pred_tta, axis=-1)\n",
        "            iou_tta = iou_per_class(mask_true_one_hot, mask_pred_tta[np.newaxis, ...]); per_class_iou_tta_list.append(iou_tta.numpy())\n",
        "\n",
        "        # Calcular promedios finales y mostrar tabla\n",
        "        avg_iou_normal = np.mean(per_class_iou_normal_list, axis=0); avg_iou_crf = np.mean(per_class_iou_crf_list, axis=0); avg_iou_tta = np.mean(per_class_iou_tta_list, axis=0)\n",
        "\n",
        "        print(\"\\n--- Resultados Detallados por Clase y Técnica ---\")\n",
        "        print(f\"{'Clase':<15} | {'IoU Normal':<12} | {'IoU con CRF':<12} | {'IoU con TTA':<12}\")\n",
        "        print(\"-\" * 65)\n",
        "        for i, class_name in enumerate(CLASS_NAMES):\n",
        "            print(f\"{class_name:<15} | {avg_iou_normal[i]:<12.4f} | {avg_iou_crf[i]:<12.4f} | {avg_iou_tta[i]:<12.4f}\")\n",
        "\n",
        "        print(\"-\" * 65)\n",
        "        mIoU_normal = np.mean(avg_iou_normal); mIoU_crf = np.mean(avg_iou_crf); mIoU_tta = np.mean(avg_iou_tta)\n",
        "        print(f\"{'mIoU Promedio':<15} | {mIoU_normal:<12.4f} | {mIoU_crf:<12.4f} | {mIoU_tta:<12.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR: Ocurrió un problema durante la ejecución: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Descomprimir el dataset (esto solo se hace una vez)\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_path = '/content/Balanced.zip'\n",
        "extract_path = '/content/'\n",
        "\n",
        "# Solo descomprimir si no se ha hecho antes\n",
        "if not os.path.exists(os.path.join(extract_path, 'Balanced')):\n",
        "    print(f\"Descomprimiendo {zip_path}...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"¡Descompresión completada!\")\n",
        "else:\n",
        "    print(\"La carpeta 'Balanced' ya existe. Omitiendo descompresión.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_IgKaIiH6zp",
        "outputId": "c81e0bb3-f831-43f3-bb9b-a4b57f66d217"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descomprimiendo /content/Balanced.zip...\n",
            "¡Descompresión completada!\n"
          ]
        }
      ]
    }
  ]
}